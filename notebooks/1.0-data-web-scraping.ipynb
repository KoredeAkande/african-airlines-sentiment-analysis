{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# African Airlines Sentiment Analysis (2015-Present)\n",
    "**Data Extraction** | Extracting Customer Reviews from 2015 on the Top African Airlines as of 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling results from [Routes Online](https://www.routesonline.com/news/29/breaking-news/287576/these-are-the-top-ten-largest-african-carriers-/) and [Skytrax](https://www.worldairlineawards.com/best-airlines-2019-by-region/), these are the top African airlines in no particular order:\n",
    "- Ethiopian Airlines\n",
    "- South African Airways\n",
    "- Air Mauritius\n",
    "- EgyptAir\n",
    "- Royal Air Maroc\n",
    "- Air Algerie\n",
    "- Comair\n",
    "- Kenya Airways\n",
    "- Tunisair\n",
    "- Fastjet\n",
    "- Air Seychelles\n",
    "- FlySafair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrape HTML content from page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_scraper(webpage):\n",
    "    \n",
    "    #Get HTML content from page\n",
    "    URL = webpage\n",
    "    page = requests.get(URL)\n",
    "    \n",
    "    #Create html parser object with beautiful soup\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    \n",
    "    #Get all the reviews on the page\n",
    "    all_reviews = soup.findAll('article')\n",
    "    reviews = all_reviews[0].findAll('article')\n",
    "\n",
    "    #List to store the data of each review\n",
    "    reviews_list = []\n",
    "    \n",
    "    #Iterate through all the reviews\n",
    "    for review in reviews:\n",
    "    \n",
    "        #Dictionary to store the data for each review\n",
    "        review_data = {}\n",
    "\n",
    "        \"\"\"\n",
    "        Extracting the review date\n",
    "        \"\"\"\n",
    "\n",
    "        #Get the date the review was published\n",
    "        date_published = dt.strptime(review.find('time',{'itemprop': 'datePublished'})['datetime'], '%Y-%M-%d')\n",
    "        \n",
    "        #If the review is published before 2015, terminate scraping\n",
    "        if date_published < dt.strptime('2015','%Y'):\n",
    "            \n",
    "            #Return True (indicating scraping should be terminated) and the current df\n",
    "            return True, pd.DataFrame(reviews_list)\n",
    "        \n",
    "        else:\n",
    "            review_data['date_published'] = date_published\n",
    "\n",
    "        \"\"\"\n",
    "        Extracting the review content and verification status\n",
    "        \"\"\"\n",
    "\n",
    "        #Get the review content\n",
    "        review_content = review.find('div',{'class': 'text_content'}).text.split('|')\n",
    "\n",
    "        if len(review_content) > 1: #i.e. there is a verification tag\n",
    "            \n",
    "            #Indicate if the review is verified or not, and note in dictionary\n",
    "            review_data['verified'] = False if 'Not' in review_content[0] else True\n",
    "            \n",
    "            #Get the actual review text, removing the trip verification tag\n",
    "            review_data['review_text'] = review_content[1].strip()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #No verification tag, get review text\n",
    "            review_data['verified'] = np.nan\n",
    "            \n",
    "            #Get the actual review text, removing the trip verification tag\n",
    "            review_data['review_text'] = review_content[0].strip()\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Extracting the review ratings\n",
    "        \"\"\"\n",
    "\n",
    "        #Get the ratings table \n",
    "        ratings_table = review.find('table',{'class': 'review-ratings'})\n",
    "\n",
    "        #Get all the attributes being rated on\n",
    "        ratings = ratings_table.find_all('tr')\n",
    "\n",
    "        #For all the attributes\n",
    "        for rating in ratings:\n",
    "\n",
    "            #Get the attribute name\n",
    "            rating_name = rating.find('td').text.lower().replace(' ','_')\n",
    "\n",
    "            #Get the characteristic or the rating where relevant\n",
    "            try:\n",
    "                review_data[rating_name.lower()] = rating.find('td',{'class':'review-value'}).text\n",
    "            except:\n",
    "                review_data[rating_name.lower()] = len(rating.find_all('span',{'class': 'star fill'}))\n",
    "        \n",
    "        #Store the record in a list – this list will ultimately be transformed to a dataframe\n",
    "        reviews_list.append(review_data)\n",
    "        \n",
    "    return False, pd.DataFrame(reviews_list)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_page_scraper(airline):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Function to scrape review data from multiple pages\n",
    "    \n",
    "    Inputs:\n",
    "        - airline (int): Indicator for the airline to scrape data on\n",
    "        - num_pages (int): The number of pages to scrape from, where each page yields 100 reviews (if available)\n",
    "        \n",
    "    Output:\n",
    "        - merged_df (pd DataFrame): A DataFrame of the reviews from all the pages\n",
    "    \"\"\"\n",
    "    \n",
    "    #Empty dataframe to store the page reviews\n",
    "    merged_df = pd.DataFrame()\n",
    "    \n",
    "    \"\"\"\n",
    "    Multi-page scraping:\n",
    "    \"\"\"\n",
    "    \n",
    "    #Variable to track if the page iterations should be terminated\n",
    "    terminate = False\n",
    "    \n",
    "    #Start search from page 1\n",
    "    pg = 1\n",
    "    \n",
    "    #Iterate through pages until a review from later than 2015 is encountered\n",
    "    while not terminate:\n",
    "        \n",
    "        #Try to scrape the page\n",
    "        try:\n",
    "            \n",
    "            webpage = f'https://www.airlinequality.com/airline-reviews/{airline}/page/{str(pg)}/?sortby=post_date%3ADesc&pagesize=100'\n",
    "            \n",
    "            terminate, df = reviews_scraper(webpage)\n",
    "\n",
    "            #Note the airline\n",
    "            df.insert(0,'Subject',airline)\n",
    "        \n",
    "            #Add the scraped reviews to the merged_df\n",
    "            merged_df = merged_df.append(df)\n",
    "            \n",
    "            #Go to the next page\n",
    "            pg += 1\n",
    "        \n",
    "        #If any error (most likely page does not exist i.e. reviews finished), terminate scraping for the airline\n",
    "        except:\n",
    "            \n",
    "            terminate = True\n",
    "        \n",
    "    #Reformat airline name\n",
    "    airline_name = airline.replace('-','_')\n",
    "        \n",
    "    #Returns the airline name and the dataframe\n",
    "    return airline_name, merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get and write scraped data to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = ['ethiopian-airlines','south-african-airways','air-mauritius',\n",
    "            'egyptair','royal-air-maroc','air-algerie','comair','kenya-airways',\n",
    "            'tunisair','fastjet','air-seychelles','flysafair']\n",
    "\n",
    "for airline in airlines:\n",
    "    airline_name, df = multi_page_scraper(airline)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    #Write dataframe to csv\n",
    "    df.to_csv(f'../data/raw/{airline_name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A brief showcase of what the dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>date_published</th>\n",
       "      <th>verified</th>\n",
       "      <th>review_text</th>\n",
       "      <th>type_of_traveller</th>\n",
       "      <th>seat_type</th>\n",
       "      <th>route</th>\n",
       "      <th>date_flown</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_staff_service</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>recommended</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>food_&amp;_beverages</th>\n",
       "      <th>inflight_entertainment</th>\n",
       "      <th>wifi_&amp;_connectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flysafair</td>\n",
       "      <td>2021-01-27 00:09:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Terrible.....they state they are the most on t...</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Johannesburg to Durban</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flysafair</td>\n",
       "      <td>2021-01-27 00:09:00</td>\n",
       "      <td>False</td>\n",
       "      <td>Cape Town to Lanseria and Lanseria to Cape Tow...</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Cape Town to Lanseria</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Boeing 737-800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flysafair</td>\n",
       "      <td>2021-01-23 00:09:00</td>\n",
       "      <td>False</td>\n",
       "      <td>My parents booked a flight for the 22nd of Sep...</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Johannesburg to George</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flysafair</td>\n",
       "      <td>2021-01-17 00:09:00</td>\n",
       "      <td>True</td>\n",
       "      <td>Everything went smoothly. I didn’t expect much...</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>East London to Johannesburg</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Boeing 737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flysafair</td>\n",
       "      <td>2021-01-14 00:08:00</td>\n",
       "      <td>True</td>\n",
       "      <td>We were already on the aircraft and it had sta...</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Cape Town to Johannesburg</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject      date_published verified  \\\n",
       "0  flysafair 2021-01-27 00:09:00     True   \n",
       "1  flysafair 2021-01-27 00:09:00    False   \n",
       "2  flysafair 2021-01-23 00:09:00    False   \n",
       "3  flysafair 2021-01-17 00:09:00     True   \n",
       "4  flysafair 2021-01-14 00:08:00     True   \n",
       "\n",
       "                                         review_text type_of_traveller  \\\n",
       "0  Terrible.....they state they are the most on t...    Family Leisure   \n",
       "1  Cape Town to Lanseria and Lanseria to Cape Tow...    Couple Leisure   \n",
       "2  My parents booked a flight for the 22nd of Sep...    Couple Leisure   \n",
       "3  Everything went smoothly. I didn’t expect much...          Business   \n",
       "4  We were already on the aircraft and it had sta...    Family Leisure   \n",
       "\n",
       "       seat_type                        route      date_flown  seat_comfort  \\\n",
       "0  Economy Class       Johannesburg to Durban  September 2021           1.0   \n",
       "1  Economy Class        Cape Town to Lanseria  September 2021           4.0   \n",
       "2  Economy Class       Johannesburg to George  September 2021           NaN   \n",
       "3  Economy Class  East London to Johannesburg  September 2021           4.0   \n",
       "4  Economy Class    Cape Town to Johannesburg     August 2021           2.0   \n",
       "\n",
       "   cabin_staff_service  ground_service  value_for_money recommended  \\\n",
       "0                  1.0             3.0              1.0          no   \n",
       "1                  5.0             5.0              4.0         yes   \n",
       "2                  NaN             1.0              1.0          no   \n",
       "3                  5.0             5.0              5.0         yes   \n",
       "4                  1.0             1.0              1.0          no   \n",
       "\n",
       "         aircraft  food_&_beverages  inflight_entertainment  \\\n",
       "0             NaN               NaN                     NaN   \n",
       "1  Boeing 737-800               NaN                     NaN   \n",
       "2             NaN               NaN                     NaN   \n",
       "3      Boeing 737               NaN                     NaN   \n",
       "4             NaN               NaN                     NaN   \n",
       "\n",
       "   wifi_&_connectivity  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge the dataframe of all the airlines together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'../data/raw' #File path with all data for the respective airlines\n",
    "all_files = glob(filepath + \"/*.csv\") #Reference all the files\n",
    "\n",
    "#List to store the files as dataframes\n",
    "files_list = []\n",
    "\n",
    "#Iterating through all the files\n",
    "for filename in all_files:\n",
    "    \n",
    "    #Read the csv and append to the files_list\n",
    "    df = pd.read_csv(filename,index_col=0)\n",
    "    files_list.append(df)\n",
    "\n",
    "#Form a merged dataframe with data on all airlines\n",
    "airlines_df = pd.concat(files_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df.to_csv(f'../data/raw/african_airlines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1256, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
